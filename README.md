# greenfrog-automation

This repository implements the automation framework with following tasks:

## Understanding the Automation Framework Structure

1. [`.github`](.github) directory

   - This directory has PR template [PULL_REQUEST_TEMPLATE.md](.github/PULL_REQUEST_TEMPLATE.md) for raising the PR in this repo.
   - We can add github actions for CI/CD as well in this directory.

2. [`allure-results`](allure-results) directory

   - This is the allure report generated files to generate allure report
   - This directory gets created automatically when the pytest command is executed with following prompt
     ```bash
     pytest src --alluredir=allure-results
     ```

3. [`logs`](logs) directory

   - I have integrated the logging for testcases and wherever i think these will help us in debugging the testcases failures.
   - This directory is automatically created, logging related configs are present in [`pytest.ini`](pytest.ini) file
   - [`execution.log`](logs/execution.log) : file automatically generated under this directory when pytest command is used for running the automation

4. [`screenshots`](screenshots) directory

   - [`screenshots/allure_report`](screenshots/allure_report) directory
     - This directory has screenshots from allure report to have overview how it looks like.
   - [`screenshots/pytest-report`](screenshots/pytest-report) directory
     - This directory has screenshots the html report generated by pytest as single file
     - The actual html report path is [`report.html`](report.html)
   - [`screenshots/test_execution`](screenshots/test_execution) directory
     - This directory has console output for pytest execution, [this is how](screenshots/test_execution/pytest_execution_output.txt) it looks like when any test is executed using pytest.

5. [`src`](src) directory

   - [`src/helpers`](src/helpers) directory

     - This directory contains the helpers which are needed for task1, task2 and task3 given in assignment.
     - [`log_parser_helper.py`](src/helpers/log_parser_helper.py) : is the helper related to logfile parsing
     - [`nasa_ssd_api_helper.py`](src/helpers/nasa_ssd_api_helper.py) : is the helper for NASA CAD SBDB API, i created incase we have all CRUD operations, other than GET, rest of all methods are commented and for future implementation.

   - [`src/tests`](src/tests) directory

     - [`conftest.py`](src/tests/conftest.py) : fixtures methods for pytest related to all tests.
     - [`test_task1_log_parser.py`](src/tests/test_task1_log_parser.py) : this test file has testcases as asked in task1 for log parsing which are using helpers from [`log_parser_helper.py`](src/helpers/log_parser_helper.py)
     - [`test_task2_nasa_ssd_api.py`](src/tests/test_task2_nasa_ssd_api.py) : this test file has testcases as asked in task2 related to NASA CAD API and using [`nasa_ssd_api_helper.py`](src/helpers/nasa_ssd_api_helper.py) as helpers.
     - [`test_task3_combined.py`](src/tests/test_task3_combined.py) : this test file contains the testcases asked in task3 related input given as logfile and successrate, internally it is using helpers from [`log_parser_helper.py`](src/helpers/log_parser_helper.py). Here i am using pytest parametrize because we want to run the test present for multiple logs files and input successrates.

   - [`src/conftest.py`](src/conftest.py) file

     - Global conftest file used to define session-wide fixtures. Enables scalability if you we need modular test folders like `tests/module1/`, `tests/module2/`, etc.
     - rightnow this files has fixture method for separating the logs in log file [`execution.log`](logs/execution.log).
     - Here are the sample logs with start and end of testcases `test_is_msg3_failure` and `test_extract_hour`
       ````bash
       -------------------------------------------------------------
       2025-06-30 11:44:27 [INFO] Execution started for : test_is_msg3_failure
       2025-06-30 11:44:27 [INFO] Found 26 failures in logfile
       2025-06-30 11:44:27 [INFO] Execution finished for : test_is_msg3_failure
       2025-06-30 11:44:27 [INFO] -------------------------------------------------------------
       2025-06-30 11:44:27 [INFO] Execution started for : test_extract_hour
       2025-06-30 11:44:27 [INFO] Checking for exact hour logs for hour 2023-08-21 12
       2025-06-30 11:44:27 [INFO] Execution finished for : test_extract_hour
       2025-06-30 11:44:27 [INFO] -------------------------------------------------------------```
       ````

   - [`src/constants.py`](src/constants.py) file
     - This file has constants and confs used by all tests files

6. [`test_data`](test_data) directory

   - [`test_data/logs`](test_data/logs) : directory
     - This directory has input log files for log parsing task and tests
   - [`test_data/testcases`](test_data/testcases) : This has the file [`Assignment_Testcases.xlsx`](test_data/testcases/Assignment_Testcases.xlsx), This has the testcases information which i have automated in this assignment

7. [`.gitignore`](.gitignore) file

   - Typical python gitignore file
   - I have added [`allure-results`](allure-results) and [`logs`](logs) as well in gitignore file

8. [`pytest.ini`](pytest.ini) file

   - This file controls the flow of pytest framework
   - This has by default used pytest options under addopts for verbose and default html report e.g. `-v --html=report.html --self-contained-html`.
   - The logging infra is controlled using the option provided in this file, you can tweak the logging configurations (e.g. `INFO`, `DEBUG` log level or `logging format` ) presents here based on your requirements.

9. [`report.html`](report.html) file

   - This is the pytest html file generated by pytest, incase you don't want to use allure reporting, you can see the results in this html for pass/fail of testcases.

10. [`README.md`](README.md) file

    - It contains the description about assigment
    - Framework structure understanding for all references
    - How to setup automation, steps for all

11. [`requirements.txt`](requirements.txt) file

    - This file has all requirements related to python packages which we need while working on this repository
    - we need to install all of these in our virtual environment

12. [`setup.py`](setup.py) file
    - This builds and packages scripts for this automation framework

> Note: `__init__.py` is added in every directory used as a Python package to enable proper module resolution.

## Setup Instructions for Automation Framework

1. Verify if Python is installed (we need 3.11 or later):

   ```bash
   which python3
   ```

2. If Python isn't installed, download and install it from [Python website](https://www.python.org/downloads/). If available, skip this step

3. Take clone of the repo, incase you want take the clone from github (private repo as of now)

   ```bash
   git clone git@github.com:siddharthagout/otto-mation-framework.git
   ```

   > Note: Incase you have zip file of this repo, than you don't need to do this step.

4. Goto framework directory

   ```bash
   cd otto-mation-framework
   ```

5. Create and Activate a Virtual Environment

   > Note: Incase you have extracted this repository from zip file, please delete the `.venv` or `venv` directories if any of these present and after that start creating your virtual environment using below steps.

   ```bash
   # For Mac/Linux
   # create virtual env
   python3 -m venv venv

   # activate virtual env
   source venv/bin/activate

   # For Windows
   # .\venv\Scripts\activate
   ```

6. Install Dependencies

   ```bash
   pip install -r requirements.txt
   ```

7. Install the Framework Locally (Editable Mode)

   ```bash
   pip install -e .
   ```

   This allows you to import project modules without needing absolute paths.

## Running automation Tests

1. Running log parser testcases

   ```bash
   pytest src/tests/test_task1_log_parser.py
   ```

2. Running NASA SSD CAD API testcases

   ```bash
   pytest src/tests/test_task2_nasa_ssd_api.py
   ```

3. Running calculation of success rate from input logfile

   ```bash
   pytest src/tests/test_task3_combined.py
   ```

4. Incase you want to run all testcases at once
   ```bash
   pytest src
   ```

## Allure Reporting (Optional)

### `Notes` - There are few compatibility issues between pytest and allure as of now, so open code repo in vscode or pycharm to make it work

- Incase you don't want to setup allure reporting, you can still see the testcases execution results in [`report.html`](report.html) report, this is generated when you execute the tests using pytest, I have added the support in addopts in [`pytest.ini`](pytest.ini) for the same.
- Incase, If you want to use the allure reporting, you need to change addopts param value in [`pytest.ini`](pytest.ini)
  - Replace this `addopts = -v --html=report.html --self-contained-html`
  - with this `addopts = -v --alluredir=allure-results`

### 1. Install Allure CLI on macOS (via Homebrew)

```bash
brew install allure
allure --version
```

For other OS installation instructions, refer to: [https://allurereport.org/docs/install/](https://allurereport.org/docs/install/)

---

### 2. Generate and View the Report

```bash
# execute tests
pytest src

# generate report
allure serve allure-results
```

This will launch a browser window with the test report and the report will look like the screenshots present @[`screenshots/allure_report`](screenshots/allure_report)

---

## Notes

- Logging is enabled across all tests to help in debugging.
- Fixtures are reusable across tasks and help abstract log reading and data setup.
- The framework is designed with modularity and scalability in mind for future task scalability and robustness.
- I have added as much as possible details in this readme.md but incase any if not working, please let me know on +919900453417 or siddharthagoutam3@gmail.com.
